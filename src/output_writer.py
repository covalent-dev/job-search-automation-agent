"""
Output Writer - Exports job data to JSON and Markdown
"""

import json
import shutil
import logging
from pathlib import Path
from datetime import datetime
from typing import List
from models import Job, SearchQuery, SearchResults

logger = logging.getLogger(__name__)


class OutputWriter:
    """Handles exporting job data to various formats"""

    def __init__(self, config):
        self.config = config

    def _ensure_output_dir(self, path: Path) -> None:
        """Create output directory if it doesn't exist"""
        path.parent.mkdir(parents=True, exist_ok=True)

    def write_json(self, jobs: List[Job], queries: List[SearchQuery]) -> Path:
        """Export jobs to JSON file"""
        output_path = self.config.get_output_path('json')
        self._ensure_output_dir(output_path)

        results = SearchResults(
            queries=queries,
            jobs=jobs,
            total_jobs=len(jobs)
        )

        with open(output_path, 'w') as f:
            json.dump(results.model_dump(), f, indent=2, default=str)

        logger.info(f"JSON written: {output_path}")
        print(f"ðŸ’¾ JSON saved: {output_path}")
        return output_path

    def write_markdown(self, jobs: List[Job], queries: List[SearchQuery]) -> Path:
        """Export jobs to Markdown file"""
        output_path = self.config.get_output_path('markdown')
        self._ensure_output_dir(output_path)

        lines = []

        # Header
        lines.append("# ðŸ” Job Search Results\n")
        lines.append(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
        lines.append(f"**Total Jobs:** {len(jobs)}\n")

        # Search queries
        lines.append("## Search Queries\n")
        for q in queries:
            lines.append(f"- {q.keyword} ({q.location})")
        lines.append("\n---\n")

        # Jobs by company
        lines.append("## Job Listings\n")

        if not jobs:
            lines.append("*No jobs found.*\n")
        else:
            for i, job in enumerate(jobs, 1):
                lines.append(f"### {i}. {job.title}\n")
                lines.append(f"**Company:** {job.company}  ")
                lines.append(f"**Location:** {job.location}  ")
                if job.salary:
                    lines.append(f"**Salary:** {job.salary}  ")
                if job.date_posted:
                    lines.append(f"**Posted:** {job.date_posted}  ")
                if job.ai_score is not None:
                    lines.append(f"**AI Score:** {job.ai_score}/10  ")
                lines.append(f"\n**Link:** [{job.title}]({job.link})\n")
                if job.description:
                    lines.append(f"> {job.description[:300]}{'...' if len(job.description) > 300 else ''}\n")
                if job.ai_reasoning:
                    reasoning = job.ai_reasoning[:180]
                    suffix = "..." if len(job.ai_reasoning) > 180 else ""
                    lines.append(f"**AI Notes:** {reasoning}{suffix}\n")
                lines.append("")

        # Summary table
        lines.append("---\n")
        lines.append("## Summary Table\n")
        lines.append("| # | Title | Company | Location | Salary | AI |")
        lines.append("|---|-------|---------|----------|--------|----|")
        for i, job in enumerate(jobs, 1):
            salary = job.salary if job.salary else "-"
            title_short = job.title[:40] + "..." if len(job.title) > 40 else job.title
            ai_score = f"{job.ai_score}/10" if job.ai_score is not None else "-"
            lines.append(f"| {i} | {title_short} | {job.company} | {job.location} | {salary} | {ai_score} |")

        lines.append("\n---\n")
        lines.append(f"*Generated by Job Search Automation*")

        with open(output_path, 'w') as f:
            f.write('\n'.join(lines))

        logger.info(f"Markdown written: {output_path}")
        print(f"ðŸ“ Markdown saved: {output_path}")
        return output_path

    def sync_to_vault(self, files: dict) -> None:
        """Copy output files to Obsidian vault if enabled"""
        if not self.config.is_vault_sync_enabled():
            return

        vault_path = self.config.get_vault_path()
        if not vault_path:
            logger.warning("Vault sync enabled but no vault_path configured")
            return

        vault_path.mkdir(parents=True, exist_ok=True)

        for file_type, source_path in files.items():
            if source_path and source_path.exists():
                dest_path = vault_path / source_path.name
                shutil.copy2(source_path, dest_path)
                logger.info(f"Synced to vault: {dest_path}")
                print(f"ðŸ“ Synced to Obsidian: {dest_path}")

    def write_all(self, jobs: List[Job], queries: List[SearchQuery]) -> dict:
        """Write all output formats and sync to vault"""
        files = {
            'json': self.write_json(jobs, queries),
            'markdown': self.write_markdown(jobs, queries)
        }

        self.sync_to_vault(files)

        return files
